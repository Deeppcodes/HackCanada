<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mock Mate</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .gradient-bg {
            background: linear-gradient(135deg, #1f2937, #111827);
        }
        .glassmorphism {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .hover-scale {
            transition: transform 0.2s ease-in-out;
        }
        .hover-scale:hover {
            transform: scale(1.02);
        }
    </style>
</head>
<body class="gradient-bg text-white">
    <div class="container mx-auto p-8">
        <!-- Title and Logo Section -->
        <div class="flex items-center mb-8 p-6 rounded-lg glassmorphism hover-scale">
            <h1 class="text-4xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-purple-400 to-pink-600">Mate Mock</h1>
        </div>

        <!-- Welcome Note with Animation -->
        <div id="welcomeContainer" class="mb-12 p-12 mx-auto text-center glassmorphism rounded-lg hover-scale">
            <h1 id="welcomeLine1" class="text-4xl font-bold text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-purple-600"></h1>
            <h2 id="welcomeLine2" class="text-xl font-semibold text-gray-300 mt-4"></h2>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
            <!-- Camera Section -->
            <div class="glassmorphism p-6 rounded-lg hover-scale">
                <h2 class="text-2xl font-semibold mb-4 text-center">üì∏<span class="text-transparent bg-clip-text bg-gradient-to-r from-green-600 to-blue-600">Live Camera</span></h2>
                <video id="liveCamera" class="bg-black w-full h-64 rounded-lg mb-4 shadow-lg" autoplay muted playsinline></video>
                <button id="startStopRecording" class="w-full bg-gradient-to-r from-green-600 to-blue-600 py-3 px-6 rounded-lg text-white font-semibold hover:from-green-700 hover:to-blue-700 transition-all">
                    ‚ñ∂ Start Recording
                </button>
                <button id="retryRecording" class="w-full bg-gradient-to-r from-green-600 to-blue-600 py-3 px-6 rounded-lg mt-4 text-white font-semibold hover:from-green-700 hover:to-blue-700 transition-all flex items-center justify-center">
                    üîÅ Retry
                </button>
            </div>

            <!-- Transcription Section -->
            <div class="glassmorphism p-6 rounded-lg hover-scale">
                <h2 class="text-2xl text-center font-semibold mb-4 text-transparent bg-clip-text bg-gradient-to-r from-purple-600 to-pink-600">Transcription</h2>
                <textarea id="transcription" class="w-full h-64 p-4 bg-gray-700 rounded-lg resize-none text-white placeholder-gray-400" placeholder="Transcript will appear here..." readonly></textarea>
                <button id="getFeedback" class="w-full bg-gradient-to-r from-purple-600 to-pink-600 py-3 px-6 rounded-lg mt-4 text-white font-semibold hover:from-purple-700 hover:to-pink-700 transition-all flex items-center justify-center">
                    <img src="https://registry.npmmirror.com/@lobehub/icons-static-png/1.24.0/files/dark/gemini-color.png" alt="Gemini AI Icon" class="w-6 h-6 mr-2"> Get Feedback
                </button>
                <div id="feedback" class="mt-4 bg-gray-700 p-4 rounded-lg text-white hidden"></div>
            </div>
        </div>

        <!-- How It Works Section -->
        <div class="mt-12 p-8 glassmorphism rounded-lg hover-scale">
            <h3 class="text-3xl font-semibold mb-6 text-transparent bg-clip-text bg-gradient-to-r from-purple-400 to-pink-600">About us</h3>
            <p class="mb-6 text-gray-300">
                We help you make the best impression possible with employers. Upload a video of your self-introduction and receive genuine, unbiased feedback that helps you improve.
            </p>
            <ul class="list-disc pl-6 space-y-3 text-gray-300">
                <li>Record your introduction using our easy-to-use interface</li>
                <li>Get instant AI-powered feedback on your presentation</li>
                <li>Improve your delivery based on actionable insights</li>
            </ul>
        </div>
    </div>

    <script>
        const liveCamera = document.getElementById('liveCamera');
        const startStopButton = document.getElementById('startStopRecording');
        const retryButton = document.getElementById('retryRecording');
        const transcriptArea = document.getElementById('transcription');
        const getFeedbackButton = document.getElementById('getFeedback');
        const feedbackBox = document.getElementById('feedback');
        const welcomeLine1 = document.getElementById('welcomeLine1');
        const welcomeLine2 = document.getElementById('welcomeLine2');
        
        let sentimentResult;
        let mediaRecorder;
        let isRecording = false;
        let chunks = [];

        // Typing animation for welcome message
        const welcomeMessage1 = "Welcome to our platform!";
        const welcomeMessage2 = "Record your introduction and get AI-powered feedback.";
        let charIndex1 = 0;
        let charIndex2 = 0;

        function typeWelcomeMessage() {
            if (charIndex1 < welcomeMessage1.length) {
                welcomeLine1.textContent += welcomeMessage1.charAt(charIndex1);
                charIndex1++;
                setTimeout(typeWelcomeMessage, 50);
            } else if (charIndex2 < welcomeMessage2.length) {
                welcomeLine2.textContent += welcomeMessage2.charAt(charIndex2);
                charIndex2++;
                setTimeout(typeWelcomeMessage, 50);
            }
        }
        typeWelcomeMessage();

        // Access the user's camera
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
                liveCamera.srcObject = stream;
                liveCamera.play(); // Ensure the video plays
            } catch (error) {
                console.error('Error accessing camera:', error);
                alert('Failed to access camera. Please allow permissions and refresh the page.');
            }
        }

        startCamera(); // Start the camera when the page loads

        // Start/Stop recording
        startStopButton.addEventListener('click', () => {
            if (isRecording) {
                mediaRecorder.stop();
                startStopButton.textContent = '‚ñ∂ Start Recording';
                startStopButton.classList.remove('bg-red-600', 'hover:bg-red-500');
            } else {
                chunks = [];
                mediaRecorder = new MediaRecorder(liveCamera.srcObject, { mimeType: 'video/mp4' });
                mediaRecorder.ondataavailable = (event) => {
                    chunks.push(event.data);
                };
                mediaRecorder.onstop = async () => {
                    const blob = new Blob(chunks, { type: 'video/mp4' });

                    // Send the recorded video to the backend for transcription
                    const formData = new FormData();
                    formData.append('video', blob, 'recording.mp4');

                    try {
                        // Transcribe the video
                        const transcriptionResponse = await fetch('/transcribe_video', {
                            method: 'POST',
                            body: formData,
                        });

                        if (!transcriptionResponse.ok) {
                            throw new Error('Failed to transcribe video');
                        }

                        const transcriptionResult = await transcriptionResponse.json();
                        transcriptArea.value = transcriptionResult.transcription;

                        // Analyze the video for emotions
                        const emotionResponse = await fetch('/analyze_video', {
                            method: 'POST',
                            body: formData,
                        });

                        if (!emotionResponse.ok) {
                            throw new Error('Failed to analyze video');
                        }

                        const emotionResult = await emotionResponse.json();
                        sentimentResult = emotionResult;
                        feedbackBox.textContent = `Emotions detected: ${JSON.stringify(emotionResult, null, 2)}`;
                        feedbackBox.classList.remove('hidden');
                    } catch (error) {
                        console.error('Error processing video:', error);
                        alert('Error processing video. Please try again.');
                    }
                };
                mediaRecorder.start();
                startStopButton.textContent = '‚ùö‚ùö Stop Recording';
                startStopButton.classList.add('bg-red-600', 'hover:bg-red-500');
            }
            isRecording = !isRecording;
        });

        // Show feedback on button click
        getFeedbackButton.addEventListener('click', () => {
            feedbackBox.classList.remove('hidden');
            feedbackBox.textContent = "Processing your feedback... üéØ ";
        });

        // Retry recording
        retryButton.addEventListener('click', () => {
            transcriptArea.value = "";
            feedbackBox.textContent = "";
            feedbackBox.classList.add('hidden');
        });

        // Get feedback from Gemini
        getFeedbackButton.addEventListener('click', async () => {
            const transcription = transcriptArea.value;

            if (!transcription) {
                alert('Please record a video and generate a transcription first.');
                return;
            }

            if (!sentimentResult) {
                alert('Please record a video and generate a transcription first.');
                return;
            }

            try {
                const responseGemini = await fetch('/ask-gemini', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ sentiment: sentimentResult , speech: transcription }),
                });

                if (!responseGemini.ok) {
                    throw new Error('Failed to get feedback');
                }

                const resultGemini = await responseGemini.json();
                console.log('Gemini response:', resultGemini);

                let trimmedResult = resultGemini.split("#");
                console.log('Trimmed response:', trimmedResult);

                trimmedResult[1] = trimmedResult[1].replace(/(?:\r\n|\r|\n)/g, '<br>');
                
                feedbackBox.textContent = `Gemini Feedback: ${trimmedResult[1]}`;
                feedbackBox.classList.remove('hidden');
            } catch (error) {
                console.error('Error getting feedback:', error);
                alert('Error getting feedback. Please try again.');
            }
        });
    </script>
</body>
</html>